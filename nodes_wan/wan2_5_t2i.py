"""
Wan 2.5 æ–‡ç”Ÿå›¾èŠ‚ç‚¹
ä½¿ç”¨ DashScope ImageSynthesis API å®ç°æ–‡å­—ç”Ÿæˆå›¾åƒåŠŸèƒ½
"""

from inspect import cleandoc
import io
import time
from http import HTTPStatus

import torch
import numpy as np
from PIL import Image

try:
    import dashscope
    from dashscope import ImageSynthesis
    import requests

    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False


# æ”¯æŒçš„å›¾ç‰‡å°ºå¯¸
SUPPORTED_SIZES = [
    "1024*1024",
    "768*1024",
    "1024*768",
    "720*1280",
    "1280*720",
]


class Wan2_5T2I:
    """
    Wan 2.5 æ–‡ç”Ÿå›¾èŠ‚ç‚¹ - ä½¿ç”¨ DashScope ImageSynthesis API
    é€šè¿‡æ–‡å­—æè¿°ç”Ÿæˆå›¾åƒ

    æ¨¡å‹: wan2.5-t2i-preview
    æ”¯æŒåŠŸèƒ½: æ–‡å­—ç”Ÿæˆå›¾åƒï¼Œæ”¯æŒæç¤ºè¯æ‰©å±•
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"multiline": False, "default": "", "tooltip": "DashScope APIå¯†é’¥"}),
                "prompt": ("STRING", {"multiline": True, "default": "", "tooltip": "å›¾åƒç”Ÿæˆæç¤ºè¯"}),
            },
            "optional": {
                "negative_prompt": ("STRING", {"multiline": True, "default": "", "tooltip": "è´Ÿé¢æç¤ºè¯"}),
                "size": (SUPPORTED_SIZES, {"default": "1024*1024", "tooltip": "è¾“å‡ºå›¾ç‰‡å°ºå¯¸"}),
                "prompt_extend": ("BOOLEAN", {"default": True, "tooltip": "æ˜¯å¦æ‰©å±•æç¤ºè¯"}),
                "seed": (
                    "INT",
                    {
                        "default": -1,
                        "min": -1,
                        "max": 2147483647,
                        "step": 1,
                        "tooltip": "éšæœºç§å­ï¼Œ-1è¡¨ç¤ºéšæœºï¼ŒèŒƒå›´[0,2147483647]",
                    },
                ),
                "watermark": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"}),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    DESCRIPTION = cleandoc(__doc__)
    FUNCTION = "generate_image"
    CATEGORY = "FunArt/Wan"

    def download_and_convert_image(self, url):
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIçš„IMAGE tensor"""
        start_time = time.time()

        # ä¸‹è½½å›¾ç‰‡
        download_start = time.time()
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        download_time = time.time() - download_start

        # ä»å­—èŠ‚æµåˆ›å»ºPILå›¾åƒ
        pil_image = Image.open(io.BytesIO(response.content))

        # è½¬æ¢ä¸ºRGB
        if pil_image.mode != "RGB":
            pil_image = pil_image.convert("RGB")

        # è½¬æ¢ä¸ºnumpy arrayå¹¶å½’ä¸€åŒ–åˆ°[0, 1]
        img_array = np.array(pil_image).astype(np.float32) / 255.0

        # è½¬æ¢ä¸ºtensor [1, H, W, C]
        tensor = torch.from_numpy(img_array)[None,]

        elapsed_time = time.time() - start_time
        print(
            f"â±ï¸  download_and_convert_image è€—æ—¶: {elapsed_time:.3f}ç§’ (ä¸‹è½½: {download_time:.3f}ç§’, è½¬æ¢: {elapsed_time-download_time:.3f}ç§’, å°ºå¯¸: {tensor.shape})"
        )

        return tensor

    def generate_image(
        self,
        api_key,
        prompt,
        negative_prompt="",
        size="1024*1024",
        prompt_extend=True,
        seed=-1,
        watermark=False,
    ):
        """
        ä½¿ç”¨ DashScope Wan 2.5 æ¨¡å‹ç”Ÿæˆå›¾åƒï¼ˆæ–‡ç”Ÿå›¾ï¼‰
        """
        if not DASHSCOPE_AVAILABLE:
            raise ImportError("dashscope æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install dashscope requests")

        if not api_key:
            raise ValueError("è¯·æä¾› DashScope API Key")

        if not prompt:
            raise ValueError("è¯·æä¾›å›¾åƒç”Ÿæˆæç¤ºè¯")

        # è®¾ç½® API Key
        dashscope.api_key = api_key
        dashscope.base_http_api_url = "https://dashscope.aliyuncs.com/api/v1"

        # å‡†å¤‡APIè°ƒç”¨å‚æ•°
        params = {
            "model": "wan2.5-t2i-preview",
            "prompt": prompt,
            "n": 1,  # å›ºå®šç”Ÿæˆ1å¼ å›¾ç‰‡
            "size": size,
            "prompt_extend": prompt_extend,
            "watermark": watermark,
        }

        # æ·»åŠ å¯é€‰å‚æ•°
        if negative_prompt:
            params["negative_prompt"] = negative_prompt

        if seed >= 0:
            # ç¡®ä¿ seed åœ¨ DashScope API å…è®¸çš„èŒƒå›´å†… [0, 2147483647]
            valid_seed = seed % 2147483648  # 2^31
            if valid_seed != seed:
                print(f"âš ï¸  Seed {seed} è¶…å‡º API èŒƒå›´ï¼Œå·²è°ƒæ•´ä¸º {valid_seed}")
            params["seed"] = valid_seed

        # è°ƒç”¨ API
        print("ğŸš€ æ­£åœ¨è°ƒç”¨ DashScope API (æ¨¡å‹: wan2.5-t2i-preview)")
        print(f"ğŸ“ Prompt: {prompt[:100]}..." if len(prompt) > 100 else f"ğŸ“ Prompt: {prompt}")
        print(f"ğŸ“ Size: {size}")
        print(f"ğŸ”„ Prompt Extend: {prompt_extend}")

        response = ImageSynthesis.call(**params)

        print(f"ğŸ“¥ API å“åº”çŠ¶æ€: {response.status_code}")
        print(f"ğŸ“‹ Request ID: {response.request_id if hasattr(response, 'request_id') else 'N/A'}")

        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != HTTPStatus.OK:
            raise RuntimeError(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")

        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
        if not response.output or not response.output.results:
            print("=" * 60)
            print("âŒ API è°ƒç”¨å¼‚å¸¸ï¼šè¿”å›æˆåŠŸä½†æ²¡æœ‰ç”Ÿæˆå›¾ç‰‡")
            print("-" * 60)
            print(f"Status Code: {response.status_code}")
            print(f"Request ID: {response.request_id if hasattr(response, 'request_id') else 'N/A'}")
            print(f"Code: {response.code if hasattr(response, 'code') else 'N/A'}")
            print(f"Message: {response.message if hasattr(response, 'message') else 'N/A'}")
            print(f"Output: {response.output if hasattr(response, 'output') else 'N/A'}")
            print("=" * 60)

            error_msg = "API è¿”å›æˆåŠŸä½†æ²¡æœ‰ç”Ÿæˆå›¾ç‰‡ï¼Œå¯èƒ½æ˜¯é…é¢é™åˆ¶ã€é¢‘ç‡é™åˆ¶æˆ–å…¶ä»– API é—®é¢˜"
            raise RuntimeError(error_msg)

        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(response.output.results)} å¼ å›¾ç‰‡")

        # æ‰“å°æ‰©å±•åçš„æç¤ºè¯ï¼ˆå¦‚æœæœ‰ï¼‰
        result = response.output.results[0]
        if hasattr(result, "actual_prompt") and result.actual_prompt:
            print(
                f"ğŸ“ æ‰©å±•åæç¤ºè¯: {result.actual_prompt[:100]}..."
                if len(result.actual_prompt) > 100
                else f"ğŸ“ æ‰©å±•åæç¤ºè¯: {result.actual_prompt}"
            )

        # ä¸‹è½½å¹¶è½¬æ¢ç”Ÿæˆçš„å›¾ç‰‡
        output_tensor = self.download_and_convert_image(result.url)

        # è¿”å›å•å¼ å›¾ç‰‡ï¼Œshape: [1, H, W, C]
        return (output_tensor,)
