"""
Image Edit Nodes for ComfyUI
åŒ…å«å„ç§å›¾åƒç¼–è¾‘ç›¸å…³çš„èŠ‚ç‚¹ï¼Œä½¿ç”¨ä¸åŒçš„ AI æ¨¡å‹
"""

from inspect import cleandoc
import io
import base64
import time
from http import HTTPStatus

import torch
import numpy as np
from PIL import Image

try:
    import dashscope
    from dashscope import ImageSynthesis
    import requests

    DASHSCOPE_AVAILABLE = True
except ImportError:
    DASHSCOPE_AVAILABLE = False


class Wan2_5ImageEdit:
    """
    Wan 2.5 å›¾åƒç¼–è¾‘èŠ‚ç‚¹ - ä½¿ç”¨ DashScope ImageSynthesis API
    æ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€æè¿°å¯¹å›¾åƒè¿›è¡Œç¼–è¾‘å’Œåˆæˆ

    APIæ–‡æ¡£: https://bailian.console.aliyun.com/?spm=5176.fcnext.console-base_product-drawer-right.dproducts-and-services-sfm.62952f033vAVNr&tab=api#/api/?type=model&url=2982258

    æ¨¡å‹: wan2.5-i2i-preview
    æ”¯æŒåŠŸèƒ½: å¤šå›¾è¾“å…¥ï¼Œé€šè¿‡æ–‡å­—æè¿°è¿›è¡Œå›¾åƒç¼–è¾‘å’Œåˆæˆ
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {"multiline": False, "default": "", "tooltip": "DashScope APIå¯†é’¥"}),
                "prompt": ("STRING", {"multiline": True, "default": "", "tooltip": "å›¾åƒç”Ÿæˆæç¤ºè¯"}),
                "image_1": ("IMAGE", {"tooltip": "ç¬¬ä¸€å¼ è¾“å…¥å›¾åƒ"}),
            },
            "optional": {
                "image_2": ("IMAGE", {"tooltip": "ç¬¬äºŒå¼ è¾“å…¥å›¾åƒï¼ˆå¯é€‰ï¼‰"}),
                "negative_prompt": ("STRING", {"multiline": True, "default": "", "tooltip": "è´Ÿé¢æç¤ºè¯"}),
                "seed": ("INT", {"default": -1, "min": -1, "max": 2**32 - 1, "step": 1, "tooltip": "éšæœºç§å­ï¼Œ-1è¡¨ç¤ºéšæœº"}),
                "watermark": ("BOOLEAN", {"default": False, "tooltip": "æ˜¯å¦æ·»åŠ æ°´å°"}),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    DESCRIPTION = cleandoc(__doc__)
    FUNCTION = "generate_image"
    CATEGORY = "FunArt/ImageEdit"

    def tensor_to_base64(self, tensor):
        """å°†ComfyUIçš„IMAGE tensorè½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        start_time = time.time()

        # tensor shape: [B, H, W, C] æˆ– [H, W, C]
        if len(tensor.shape) == 4:
            tensor = tensor[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡

        # è½¬æ¢ä¸º numpy array (H, W, C)ï¼Œå€¼èŒƒå›´ [0, 1]
        img_array = tensor.cpu().numpy()

        # è½¬æ¢ä¸º 0-255 èŒƒå›´çš„ uint8
        img_array = np.clip(img_array * 255.0, 0, 255).astype(np.uint8)

        # è½¬æ¢ä¸º PIL Image
        pil_image = Image.fromarray(img_array, mode="RGB")

        # è½¬æ¢ä¸º bytes
        buffered = io.BytesIO()
        pil_image.save(buffered, format="PNG")
        img_bytes = buffered.getvalue()

        # Base64 ç¼–ç 
        encoded_string = base64.b64encode(img_bytes).decode("utf-8")

        elapsed_time = time.time() - start_time
        print(f"â±ï¸  tensor_to_base64 è€—æ—¶: {elapsed_time:.3f}ç§’ (å›¾ç‰‡å¤§å°: {len(encoded_string)//1024}KB)")

        # è¿”å› data URI æ ¼å¼
        return f"data:image/png;base64,{encoded_string}"

    def download_and_convert_image(self, url):
        """ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºComfyUIçš„IMAGE tensor"""
        start_time = time.time()

        # ä¸‹è½½å›¾ç‰‡
        download_start = time.time()
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        download_time = time.time() - download_start

        # ä»å­—èŠ‚æµåˆ›å»ºPILå›¾åƒ
        pil_image = Image.open(io.BytesIO(response.content))

        # è½¬æ¢ä¸ºRGB
        if pil_image.mode != "RGB":
            pil_image = pil_image.convert("RGB")

        # è½¬æ¢ä¸ºnumpy arrayå¹¶å½’ä¸€åŒ–åˆ°[0, 1]
        img_array = np.array(pil_image).astype(np.float32) / 255.0

        # è½¬æ¢ä¸ºtensor [1, H, W, C]
        tensor = torch.from_numpy(img_array)[None,]

        elapsed_time = time.time() - start_time
        print(
            f"â±ï¸  download_and_convert_image è€—æ—¶: {elapsed_time:.3f}ç§’ (ä¸‹è½½: {download_time:.3f}ç§’, è½¬æ¢: {elapsed_time-download_time:.3f}ç§’, å°ºå¯¸: {tensor.shape})"
        )

        return tensor

    def generate_image(self, api_key, prompt, image_1, image_2=None, negative_prompt="", seed=-1, watermark=False):
        """
        ä½¿ç”¨ DashScope Wan 2.5 æ¨¡å‹ç”Ÿæˆå›¾åƒï¼ˆå›¾ç”Ÿå›¾ï¼‰
        """
        if not DASHSCOPE_AVAILABLE:
            raise ImportError("dashscope æœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install dashscope requests")

        if not api_key:
            raise ValueError("è¯·æä¾› DashScope API Key")

        # è®¾ç½® API Key
        dashscope.api_key = api_key
        dashscope.base_http_api_url = "https://dashscope.aliyuncs.com/api/v1"

        # å°† IMAGE tensor è½¬æ¢ä¸º base64
        image_base64_list = [self.tensor_to_base64(image_1)]
        if image_2 is not None:
            image_base64_list.append(self.tensor_to_base64(image_2))

        # å‡†å¤‡APIè°ƒç”¨å‚æ•°
        params = {
            "model": "wan2.5-i2i-preview",
            "prompt": prompt,
            "images": image_base64_list,
            "n": 1,  # å›ºå®šç”Ÿæˆ1å¼ å›¾ç‰‡
            "watermark": watermark,
        }

        # æ·»åŠ å¯é€‰å‚æ•°
        if negative_prompt:
            params["negative_prompt"] = negative_prompt

        if seed >= 0:
            params["seed"] = seed

        # è°ƒç”¨ API
        print("ğŸš€ æ­£åœ¨è°ƒç”¨ DashScope API (æ¨¡å‹: wan2.5-i2i-preview)")
        print(f"ğŸ“ Prompt: {prompt[:100]}..." if len(prompt) > 100 else f"ğŸ“ Prompt: {prompt}")
        print(f"ğŸ–¼ï¸  å›¾ç‰‡æ•°é‡: {len(image_base64_list)}")

        response = ImageSynthesis.call(**params)

        print(f"ğŸ“¥ API å“åº”çŠ¶æ€: {response.status_code}")
        print(f"ğŸ“‹ Request ID: {response.request_id if hasattr(response, 'request_id') else 'N/A'}")

        # æ£€æŸ¥å“åº”çŠ¶æ€
        if response.status_code != HTTPStatus.OK:
            raise RuntimeError(f"APIè°ƒç”¨å¤±è´¥: {response.code} - {response.message}")

        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
        if not response.output or not response.output.results:
            print("=" * 60)
            print("âŒ API è°ƒç”¨å¼‚å¸¸ï¼šè¿”å›æˆåŠŸä½†æ²¡æœ‰ç”Ÿæˆå›¾ç‰‡")
            print("-" * 60)
            print(f"Status Code: {response.status_code}")
            print(f"Request ID: {response.request_id if hasattr(response, 'request_id') else 'N/A'}")
            print(f"Code: {response.code if hasattr(response, 'code') else 'N/A'}")
            print(f"Message: {response.message if hasattr(response, 'message') else 'N/A'}")
            print(f"Output: {response.output if hasattr(response, 'output') else 'N/A'}")
            print("=" * 60)

            error_msg = "API è¿”å›æˆåŠŸä½†æ²¡æœ‰ç”Ÿæˆå›¾ç‰‡ï¼Œå¯èƒ½æ˜¯é…é¢é™åˆ¶ã€é¢‘ç‡é™åˆ¶æˆ–å…¶ä»– API é—®é¢˜"
            raise RuntimeError(error_msg)

        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(response.output.results)} å¼ å›¾ç‰‡")

        # ä¸‹è½½å¹¶è½¬æ¢ç”Ÿæˆçš„å›¾ç‰‡ï¼ˆåªæœ‰ä¸€å¼ ï¼‰
        result = response.output.results[0]
        output_tensor = self.download_and_convert_image(result.url)

        # è¿”å›å•å¼ å›¾ç‰‡ï¼Œshape: [1, H, W, C]
        return (output_tensor,)


# èŠ‚ç‚¹ç±»æ˜ å°„ - ç”¨äºComfyUIè¯†åˆ«å’ŒåŠ è½½èŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "Wan2_5ImageEdit": Wan2_5ImageEdit,
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„ - åœ¨ComfyUIç•Œé¢ä¸­æ˜¾ç¤ºçš„å‹å¥½åç§°
NODE_DISPLAY_NAME_MAPPINGS = {
    "Wan2_5ImageEdit": "Wan 2.5 å›¾åƒç¼–è¾‘",
}
